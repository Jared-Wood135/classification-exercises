{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45b7e00e",
   "metadata": {},
   "source": [
    "<a id=\"TableOfContents\"></a>\n",
    "# Table of Contents:\n",
    "<li><a href='#imports'>Imports</a></li>\n",
    "<li><a href=\"#Q1\">Question 1</a></li>\n",
    "<li><a href=\"#Q2\">Question 2</a></li>\n",
    "<li><a href=\"#Q3\">Question 3</a></li>\n",
    "<li><a href=\"#Q4\">Question 4</a></li>\n",
    "<li><a href=\"#Q5\">Question 5</a></li>\n",
    "<li><a href=\"#Bonus1\">Bonus-1</a></li>\n",
    "<li><a href=\"#Bonus2\">Bonus-2</a></li>\n",
    "<li><a href=\"#Bonus3\">Bonus-3</a></li>\n",
    "<li><a href=\"#BonusBonus\">Bonus-Bonus</a></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83c2ead",
   "metadata": {},
   "source": [
    "<a id='imports'></a>\n",
    "### Imports:\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47d7215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Sheiza\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Stats\n",
    "from scipy import stats\n",
    "\n",
    "# Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# .py file\n",
    "import acquire\n",
    "import prepare\n",
    "import explore\n",
    "import evaluation\n",
    "\n",
    "# itertools\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda1f8b6",
   "metadata": {},
   "source": [
    "In these exercises, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d17c8cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Cherbourg</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.75</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass   sex  age   fare  embark_town  alone  sex_female  \\\n",
       "549         1       2  male  8.0  36.75  Southampton      0           0   \n",
       "\n",
       "     sex_male  embark_town_Cherbourg  embark_town_Queenstown  \\\n",
       "549         1                      0                       0   \n",
       "\n",
       "     embark_town_Southampton  \n",
       "549                        1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get titanic dataset\n",
    "titanic = prepare.prep_titanic()\n",
    "titanic.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "157b416e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pclass',\n",
       " 'age',\n",
       " 'fare',\n",
       " 'alone',\n",
       " 'sex_female',\n",
       " 'sex_male',\n",
       " 'embark_town_Cherbourg',\n",
       " 'embark_town_Queenstown',\n",
       " 'embark_town_Southampton']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify x_cols\n",
    "x_cols = [col for col in titanic if col not in ['survived', 'sex', 'embark_town']]\n",
    "x_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0d2e430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'survived'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify y_cols\n",
    "y_cols = 'survived'\n",
    "y_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4699781f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape:(498, 12)\n",
      "validate.shape:(214, 12)\n",
      "test.shape:(179, 12)\n"
     ]
    }
   ],
   "source": [
    "# Split yo' data\n",
    "train, validate, test = prepare.split(titanic, 'survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e40cf220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((498, 12), (214, 12), (179, 12))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify yo' split\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef2f8dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify yo' x/y train, validate, test\n",
    "x_train = train[x_cols]\n",
    "y_train = train[y_cols]\n",
    "x_validate = validate[x_cols]\n",
    "y_validate = validate[y_cols]\n",
    "x_test = test[x_cols]\n",
    "y_test = test[y_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "237a2c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  baseline\n",
       "474         0         0\n",
       "370         1         0\n",
       "573         1         0\n",
       "110         0         0\n",
       "167         0         0\n",
       "..        ...       ...\n",
       "735         0         0\n",
       "163         0         0\n",
       "770         0         0\n",
       "196         0         0\n",
       "94          0         0\n",
       "\n",
       "[498 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create train models df\n",
    "# Create baseline column\n",
    "train_models = pd.DataFrame(train.survived)\n",
    "train_models['baseline'] = 0\n",
    "train_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b217f3",
   "metadata": {},
   "source": [
    "<a id='Q1'></a>\n",
    "### 1. Create a model that includes only age, fare, and pclass. Does this model perform better than your baseline?\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "27529662",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_q1 = ['age', 'fare', 'pclass']\n",
    "x_q1_train = train[x_q1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "899a6c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1 = LogisticRegression()\n",
    "lr1.fit(x_q1_train, y_train)\n",
    "model1 = lr1.predict(x_q1_train)\n",
    "train_models['model1'] = model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d2ec52b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32msurvived:\u001b[0m 100.00%\n",
      "\n",
      "\u001b[32mbaseline:\u001b[0m 61.65%\n",
      "\n",
      "\u001b[32mmodel1:\u001b[0m 74.50%\n",
      "\n",
      "\u001b[31mHIGHEST VALUE =\u001b[0m \u001b[32mmodel1\u001b[0m: 74.50%\n",
      "\u001b[31mLOWEST VALUE =\u001b[0m \u001b[32mbaseline\u001b[0m: 61.65%\n"
     ]
    }
   ],
   "source": [
    "evaluation.accuracy(train_models, 'survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5899a5",
   "metadata": {},
   "source": [
    "Model-1 performs better than the baseline..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030f7daa",
   "metadata": {},
   "source": [
    "<a id='Q2'></a>\n",
    "### 2. Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model.\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "853d89b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pclass',\n",
       " 'age',\n",
       " 'fare',\n",
       " 'alone',\n",
       " 'sex_female',\n",
       " 'sex_male',\n",
       " 'embark_town_Cherbourg',\n",
       " 'embark_town_Queenstown',\n",
       " 'embark_town_Southampton']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bca85d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_q2 = ['age', 'fare', 'pclass', 'sex_female', 'sex_male']\n",
    "x_q2_train = train[x_q2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "433d9fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = LogisticRegression()\n",
    "lr2.fit(x_q2_train, y_train)\n",
    "model2 = lr2.predict(x_q2_train)\n",
    "train_models['model2'] = model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "855f9cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32msurvived:\u001b[0m 100.00%\n",
      "\n",
      "\u001b[32mbaseline:\u001b[0m 61.65%\n",
      "\n",
      "\u001b[32mmodel1:\u001b[0m 74.50%\n",
      "\n",
      "\u001b[32mmodel2:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[31mHIGHEST VALUE =\u001b[0m \u001b[32mmodel2\u001b[0m: 79.32%\n",
      "\u001b[31mLOWEST VALUE =\u001b[0m \u001b[32mbaseline\u001b[0m: 61.65%\n"
     ]
    }
   ],
   "source": [
    "evaluation.accuracy(train_models, 'survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d610a3",
   "metadata": {},
   "source": [
    "Including 'sex' columns increased accuracy..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c01e50",
   "metadata": {},
   "source": [
    "<a id='Q3'></a>\n",
    "### 3. Try out other combinations of features and models.\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a09b93a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "combos = []\n",
    "for i in range(2, len(x_cols) + 1):\n",
    "    combos += itertools.combinations(x_cols, i)\n",
    "combolist = [list(combo) for combo in combos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c76c480b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_15117/3039067025.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_models[modelnum] = model\n"
     ]
    }
   ],
   "source": [
    "modelnum = 2\n",
    "for x in combolist:\n",
    "    modelnum += 1\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(train[x], y_train)\n",
    "    model = lr.predict(train[x])\n",
    "    train_models[modelnum] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2ba98842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    traindict = {\n",
    "        'model': ['survived', 'baseline', '1', '2'],\n",
    "        'features': ['None', 'None', ['age', 'fare', 'pclass'], ['age', 'fare', 'pclass', 'sex_male', 'sex_female']],\n",
    "        'train_score': [100, 0, 0, 0],\n",
    "        'validate_score': [100, 0, 0, 0]\n",
    "    }\n",
    "    modelnum = 2\n",
    "    for x in combolist:\n",
    "        modelnum += 1\n",
    "        lr = LogisticRegression()\n",
    "        lr.fit(train[x], y_train)\n",
    "        model = lr.predict(train[x])\n",
    "        traindict['model'].append(modelnum)\n",
    "        traindict['features'].append(x)\n",
    "        traindict['train_score'].append(lr.score(train[x], y_train))\n",
    "        traindict['validate_score'].append(lr.score(validate[x], y_validate)) \n",
    "    return traindict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "494a127f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "newdict = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1ee475e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>features</th>\n",
       "      <th>train_score</th>\n",
       "      <th>validate_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>survived</td>\n",
       "      <td>None</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baseline</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[age, fare, pclass]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>[age, fare, pclass, sex_male, sex_female]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>[pclass, age]</td>\n",
       "      <td>0.728916</td>\n",
       "      <td>0.640187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>500</td>\n",
       "      <td>[pclass, age, fare, sex_female, sex_male, emba...</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>0.742991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>501</td>\n",
       "      <td>[pclass, age, alone, sex_female, sex_male, emb...</td>\n",
       "      <td>0.805221</td>\n",
       "      <td>0.738318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>502</td>\n",
       "      <td>[pclass, fare, alone, sex_female, sex_male, em...</td>\n",
       "      <td>0.803213</td>\n",
       "      <td>0.724299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>503</td>\n",
       "      <td>[age, fare, alone, sex_female, sex_male, embar...</td>\n",
       "      <td>0.787149</td>\n",
       "      <td>0.738318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>504</td>\n",
       "      <td>[pclass, age, fare, alone, sex_female, sex_mal...</td>\n",
       "      <td>0.801205</td>\n",
       "      <td>0.742991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        model                                           features  train_score  \\\n",
       "0    survived                                               None   100.000000   \n",
       "1    baseline                                               None     0.000000   \n",
       "2           1                                [age, fare, pclass]     0.000000   \n",
       "3           2          [age, fare, pclass, sex_male, sex_female]     0.000000   \n",
       "4           3                                      [pclass, age]     0.728916   \n",
       "..        ...                                                ...          ...   \n",
       "501       500  [pclass, age, fare, sex_female, sex_male, emba...     0.795181   \n",
       "502       501  [pclass, age, alone, sex_female, sex_male, emb...     0.805221   \n",
       "503       502  [pclass, fare, alone, sex_female, sex_male, em...     0.803213   \n",
       "504       503  [age, fare, alone, sex_female, sex_male, embar...     0.787149   \n",
       "505       504  [pclass, age, fare, alone, sex_female, sex_mal...     0.801205   \n",
       "\n",
       "     validate_score  \n",
       "0        100.000000  \n",
       "1          0.000000  \n",
       "2          0.000000  \n",
       "3          0.000000  \n",
       "4          0.640187  \n",
       "..              ...  \n",
       "501        0.742991  \n",
       "502        0.738318  \n",
       "503        0.724299  \n",
       "504        0.738318  \n",
       "505        0.742991  \n",
       "\n",
       "[506 rows x 4 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf = pd.DataFrame(newdict)\n",
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "351baf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32msurvived:\u001b[0m 100.00%\n",
      "\n",
      "\u001b[32mbaseline:\u001b[0m 61.65%\n",
      "\n",
      "\u001b[32mmodel1:\u001b[0m 74.50%\n",
      "\n",
      "\u001b[32mmodel2:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m3:\u001b[0m 72.89%\n",
      "\n",
      "\u001b[32m4:\u001b[0m 70.48%\n",
      "\n",
      "\u001b[32m5:\u001b[0m 74.30%\n",
      "\n",
      "\u001b[32m6:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m7:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m8:\u001b[0m 70.48%\n",
      "\n",
      "\u001b[32m9:\u001b[0m 70.28%\n",
      "\n",
      "\u001b[32m10:\u001b[0m 70.88%\n",
      "\n",
      "\u001b[32m11:\u001b[0m 67.27%\n",
      "\n",
      "\u001b[32m12:\u001b[0m 66.47%\n",
      "\n",
      "\u001b[32m13:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m14:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m15:\u001b[0m 62.85%\n",
      "\n",
      "\u001b[32m16:\u001b[0m 61.65%\n",
      "\n",
      "\u001b[32m17:\u001b[0m 62.25%\n",
      "\n",
      "\u001b[32m18:\u001b[0m 69.08%\n",
      "\n",
      "\u001b[32m19:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m20:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m21:\u001b[0m 68.88%\n",
      "\n",
      "\u001b[32m22:\u001b[0m 67.87%\n",
      "\n",
      "\u001b[32m23:\u001b[0m 68.88%\n",
      "\n",
      "\u001b[32m24:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m25:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m26:\u001b[0m 66.47%\n",
      "\n",
      "\u001b[32m27:\u001b[0m 66.47%\n",
      "\n",
      "\u001b[32m28:\u001b[0m 66.47%\n",
      "\n",
      "\u001b[32m29:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m30:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m31:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m32:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m33:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m34:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m35:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m36:\u001b[0m 63.05%\n",
      "\n",
      "\u001b[32m37:\u001b[0m 63.05%\n",
      "\n",
      "\u001b[32m38:\u001b[0m 63.05%\n",
      "\n",
      "\u001b[32m39:\u001b[0m 74.50%\n",
      "\n",
      "\u001b[32m40:\u001b[0m 74.50%\n",
      "\n",
      "\u001b[32m41:\u001b[0m 78.92%\n",
      "\n",
      "\u001b[32m42:\u001b[0m 78.92%\n",
      "\n",
      "\u001b[32m43:\u001b[0m 73.29%\n",
      "\n",
      "\u001b[32m44:\u001b[0m 73.29%\n",
      "\n",
      "\u001b[32m45:\u001b[0m 73.09%\n",
      "\n",
      "\u001b[32m46:\u001b[0m 74.30%\n",
      "\n",
      "\u001b[32m47:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m48:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m49:\u001b[0m 70.48%\n",
      "\n",
      "\u001b[32m50:\u001b[0m 70.28%\n",
      "\n",
      "\u001b[32m51:\u001b[0m 70.88%\n",
      "\n",
      "\u001b[32m52:\u001b[0m 79.52%\n",
      "\n",
      "\u001b[32m53:\u001b[0m 79.52%\n",
      "\n",
      "\u001b[32m54:\u001b[0m 74.30%\n",
      "\n",
      "\u001b[32m55:\u001b[0m 73.69%\n",
      "\n",
      "\u001b[32m56:\u001b[0m 74.30%\n",
      "\n",
      "\u001b[32m57:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m58:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m59:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m60:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m61:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m62:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m63:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m64:\u001b[0m 70.28%\n",
      "\n",
      "\u001b[32m65:\u001b[0m 70.28%\n",
      "\n",
      "\u001b[32m66:\u001b[0m 70.28%\n",
      "\n",
      "\u001b[32m67:\u001b[0m 70.08%\n",
      "\n",
      "\u001b[32m68:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m69:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m70:\u001b[0m 68.67%\n",
      "\n",
      "\u001b[32m71:\u001b[0m 67.27%\n",
      "\n",
      "\u001b[32m72:\u001b[0m 68.27%\n",
      "\n",
      "\u001b[32m73:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m74:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m75:\u001b[0m 66.27%\n",
      "\n",
      "\u001b[32m76:\u001b[0m 66.47%\n",
      "\n",
      "\u001b[32m77:\u001b[0m 66.06%\n",
      "\n",
      "\u001b[32m78:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m79:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m80:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m81:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m82:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m83:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m84:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m85:\u001b[0m 62.85%\n",
      "\n",
      "\u001b[32m86:\u001b[0m 62.65%\n",
      "\n",
      "\u001b[32m87:\u001b[0m 62.65%\n",
      "\n",
      "\u001b[32m88:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m89:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m90:\u001b[0m 70.48%\n",
      "\n",
      "\u001b[32m91:\u001b[0m 69.28%\n",
      "\n",
      "\u001b[32m92:\u001b[0m 69.68%\n",
      "\n",
      "\u001b[32m93:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m94:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m95:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m96:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m97:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m98:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m99:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m100:\u001b[0m 68.67%\n",
      "\n",
      "\u001b[32m101:\u001b[0m 68.67%\n",
      "\n",
      "\u001b[32m102:\u001b[0m 68.67%\n",
      "\n",
      "\u001b[32m103:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m104:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m105:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m106:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m107:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m108:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m109:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m110:\u001b[0m 66.47%\n",
      "\n",
      "\u001b[32m111:\u001b[0m 66.47%\n",
      "\n",
      "\u001b[32m112:\u001b[0m 66.47%\n",
      "\n",
      "\u001b[32m113:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m114:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m115:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m116:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m117:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m118:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m119:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m120:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m121:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m122:\u001b[0m 63.05%\n",
      "\n",
      "\u001b[32m123:\u001b[0m 74.90%\n",
      "\n",
      "\u001b[32m124:\u001b[0m 79.52%\n",
      "\n",
      "\u001b[32m125:\u001b[0m 79.52%\n",
      "\n",
      "\u001b[32m126:\u001b[0m 73.90%\n",
      "\n",
      "\u001b[32m127:\u001b[0m 74.30%\n",
      "\n",
      "\u001b[32m128:\u001b[0m 73.29%\n",
      "\n",
      "\u001b[32m129:\u001b[0m 78.31%\n",
      "\n",
      "\u001b[32m130:\u001b[0m 78.31%\n",
      "\n",
      "\u001b[32m131:\u001b[0m 75.30%\n",
      "\n",
      "\u001b[32m132:\u001b[0m 75.10%\n",
      "\n",
      "\u001b[32m133:\u001b[0m 75.30%\n",
      "\n",
      "\u001b[32m134:\u001b[0m 78.92%\n",
      "\n",
      "\u001b[32m135:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m136:\u001b[0m 79.12%\n",
      "\n",
      "\u001b[32m137:\u001b[0m 79.72%\n",
      "\n",
      "\u001b[32m138:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m139:\u001b[0m 79.12%\n",
      "\n",
      "\u001b[32m140:\u001b[0m 79.72%\n",
      "\n",
      "\u001b[32m141:\u001b[0m 73.29%\n",
      "\n",
      "\u001b[32m142:\u001b[0m 73.49%\n",
      "\n",
      "\u001b[32m143:\u001b[0m 73.90%\n",
      "\n",
      "\u001b[32m144:\u001b[0m 79.92%\n",
      "\n",
      "\u001b[32m145:\u001b[0m 79.92%\n",
      "\n",
      "\u001b[32m146:\u001b[0m 74.30%\n",
      "\n",
      "\u001b[32m147:\u001b[0m 73.69%\n",
      "\n",
      "\u001b[32m148:\u001b[0m 75.50%\n",
      "\n",
      "\u001b[32m149:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m150:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m151:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m152:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m153:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m154:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m155:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m156:\u001b[0m 70.28%\n",
      "\n",
      "\u001b[32m157:\u001b[0m 70.28%\n",
      "\n",
      "\u001b[32m158:\u001b[0m 70.28%\n",
      "\n",
      "\u001b[32m159:\u001b[0m 79.52%\n",
      "\n",
      "\u001b[32m160:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m161:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m162:\u001b[0m 79.92%\n",
      "\n",
      "\u001b[32m163:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m164:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m165:\u001b[0m 79.92%\n",
      "\n",
      "\u001b[32m166:\u001b[0m 73.69%\n",
      "\n",
      "\u001b[32m167:\u001b[0m 73.69%\n",
      "\n",
      "\u001b[32m168:\u001b[0m 73.69%\n",
      "\n",
      "\u001b[32m169:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m170:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m171:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m172:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m173:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m174:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m175:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m176:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m177:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m178:\u001b[0m 70.28%\n",
      "\n",
      "\u001b[32m179:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m180:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m181:\u001b[0m 70.08%\n",
      "\n",
      "\u001b[32m182:\u001b[0m 69.08%\n",
      "\n",
      "\u001b[32m183:\u001b[0m 69.88%\n",
      "\n",
      "\u001b[32m184:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m185:\u001b[0m 78.92%\n",
      "\n",
      "\u001b[32m186:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m187:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m188:\u001b[0m 78.92%\n",
      "\n",
      "\u001b[32m189:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m190:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m191:\u001b[0m 68.27%\n",
      "\n",
      "\u001b[32m192:\u001b[0m 68.27%\n",
      "\n",
      "\u001b[32m193:\u001b[0m 68.27%\n",
      "\n",
      "\u001b[32m194:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m195:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m196:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m197:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m198:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m199:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m200:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m201:\u001b[0m 66.27%\n",
      "\n",
      "\u001b[32m202:\u001b[0m 66.27%\n",
      "\n",
      "\u001b[32m203:\u001b[0m 66.47%\n",
      "\n",
      "\u001b[32m204:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m205:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m206:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m207:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m208:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m209:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m210:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m211:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m212:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m213:\u001b[0m 62.65%\n",
      "\n",
      "\u001b[32m214:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m215:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m216:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m217:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m218:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m219:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m220:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m221:\u001b[0m 69.68%\n",
      "\n",
      "\u001b[32m222:\u001b[0m 69.68%\n",
      "\n",
      "\u001b[32m223:\u001b[0m 69.68%\n",
      "\n",
      "\u001b[32m224:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m225:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m226:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m227:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m228:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m229:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m230:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m231:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m232:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m233:\u001b[0m 68.67%\n",
      "\n",
      "\u001b[32m234:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m235:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m236:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m237:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m238:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m239:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m240:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m241:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m242:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m243:\u001b[0m 66.47%\n",
      "\n",
      "\u001b[32m244:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m245:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m246:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m247:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m248:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m249:\u001b[0m 80.32%\n",
      "\n",
      "\u001b[32m250:\u001b[0m 80.32%\n",
      "\n",
      "\u001b[32m251:\u001b[0m 75.10%\n",
      "\n",
      "\u001b[32m252:\u001b[0m 75.30%\n",
      "\n",
      "\u001b[32m253:\u001b[0m 75.10%\n",
      "\n",
      "\u001b[32m254:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m255:\u001b[0m 79.92%\n",
      "\n",
      "\u001b[32m256:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m257:\u001b[0m 79.72%\n",
      "\n",
      "\u001b[32m258:\u001b[0m 79.92%\n",
      "\n",
      "\u001b[32m259:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m260:\u001b[0m 79.72%\n",
      "\n",
      "\u001b[32m261:\u001b[0m 74.10%\n",
      "\n",
      "\u001b[32m262:\u001b[0m 73.69%\n",
      "\n",
      "\u001b[32m263:\u001b[0m 74.10%\n",
      "\n",
      "\u001b[32m264:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m265:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m266:\u001b[0m 79.72%\n",
      "\n",
      "\u001b[32m267:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m268:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m269:\u001b[0m 79.72%\n",
      "\n",
      "\u001b[32m270:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m271:\u001b[0m 75.90%\n",
      "\n",
      "\u001b[32m272:\u001b[0m 75.90%\n",
      "\n",
      "\u001b[32m273:\u001b[0m 75.70%\n",
      "\n",
      "\u001b[32m274:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m275:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m276:\u001b[0m 78.92%\n",
      "\n",
      "\u001b[32m277:\u001b[0m 80.32%\n",
      "\n",
      "\u001b[32m278:\u001b[0m 80.32%\n",
      "\n",
      "\u001b[32m279:\u001b[0m 80.32%\n",
      "\n",
      "\u001b[32m280:\u001b[0m 80.32%\n",
      "\n",
      "\u001b[32m281:\u001b[0m 80.32%\n",
      "\n",
      "\u001b[32m282:\u001b[0m 80.32%\n",
      "\n",
      "\u001b[32m283:\u001b[0m 73.09%\n",
      "\n",
      "\u001b[32m284:\u001b[0m 79.92%\n",
      "\n",
      "\u001b[32m285:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m286:\u001b[0m 80.32%\n",
      "\n",
      "\u001b[32m287:\u001b[0m 79.92%\n",
      "\n",
      "\u001b[32m288:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m289:\u001b[0m 80.32%\n",
      "\n",
      "\u001b[32m290:\u001b[0m 79.92%\n",
      "\n",
      "\u001b[32m291:\u001b[0m 73.69%\n",
      "\n",
      "\u001b[32m292:\u001b[0m 73.69%\n",
      "\n",
      "\u001b[32m293:\u001b[0m 73.69%\n",
      "\n",
      "\u001b[32m294:\u001b[0m 78.31%\n",
      "\n",
      "\u001b[32m295:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m296:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m297:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m298:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m299:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m300:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m301:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m302:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m303:\u001b[0m 70.28%\n",
      "\n",
      "\u001b[32m304:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m305:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m306:\u001b[0m 79.92%\n",
      "\n",
      "\u001b[32m307:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m308:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m309:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m310:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m311:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m312:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m313:\u001b[0m 73.69%\n",
      "\n",
      "\u001b[32m314:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m315:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m316:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m317:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m318:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m319:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m320:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m321:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m322:\u001b[0m 78.92%\n",
      "\n",
      "\u001b[32m323:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m324:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m325:\u001b[0m 78.92%\n",
      "\n",
      "\u001b[32m326:\u001b[0m 70.48%\n",
      "\n",
      "\u001b[32m327:\u001b[0m 70.48%\n",
      "\n",
      "\u001b[32m328:\u001b[0m 70.48%\n",
      "\n",
      "\u001b[32m329:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m330:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m331:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m332:\u001b[0m 78.92%\n",
      "\n",
      "\u001b[32m333:\u001b[0m 78.92%\n",
      "\n",
      "\u001b[32m334:\u001b[0m 78.92%\n",
      "\n",
      "\u001b[32m335:\u001b[0m 78.92%\n",
      "\n",
      "\u001b[32m336:\u001b[0m 78.92%\n",
      "\n",
      "\u001b[32m337:\u001b[0m 78.92%\n",
      "\n",
      "\u001b[32m338:\u001b[0m 68.27%\n",
      "\n",
      "\u001b[32m339:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m340:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m341:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m342:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m343:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m344:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m345:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m346:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m347:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m348:\u001b[0m 66.27%\n",
      "\n",
      "\u001b[32m349:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m350:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m351:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m352:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m353:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m354:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m355:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m356:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m357:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m358:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m359:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m360:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m361:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m362:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m363:\u001b[0m 69.68%\n",
      "\n",
      "\u001b[32m364:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m365:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m366:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m367:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m368:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m369:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m370:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m371:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m372:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m373:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m374:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m375:\u001b[0m 80.32%\n",
      "\n",
      "\u001b[32m376:\u001b[0m 78.92%\n",
      "\n",
      "\u001b[32m377:\u001b[0m 79.52%\n",
      "\n",
      "\u001b[32m378:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m379:\u001b[0m 78.92%\n",
      "\n",
      "\u001b[32m380:\u001b[0m 79.52%\n",
      "\n",
      "\u001b[32m381:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m382:\u001b[0m 75.90%\n",
      "\n",
      "\u001b[32m383:\u001b[0m 75.70%\n",
      "\n",
      "\u001b[32m384:\u001b[0m 75.70%\n",
      "\n",
      "\u001b[32m385:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m386:\u001b[0m 78.92%\n",
      "\n",
      "\u001b[32m387:\u001b[0m 79.72%\n",
      "\n",
      "\u001b[32m388:\u001b[0m 79.92%\n",
      "\n",
      "\u001b[32m389:\u001b[0m 79.92%\n",
      "\n",
      "\u001b[32m390:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m391:\u001b[0m 79.92%\n",
      "\n",
      "\u001b[32m392:\u001b[0m 79.92%\n",
      "\n",
      "\u001b[32m393:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m394:\u001b[0m 73.90%\n",
      "\n",
      "\u001b[32m395:\u001b[0m 80.52%\n",
      "\n",
      "\u001b[32m396:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m397:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m398:\u001b[0m 80.92%\n",
      "\n",
      "\u001b[32m399:\u001b[0m 80.72%\n",
      "\n",
      "\u001b[32m400:\u001b[0m 80.92%\n",
      "\n",
      "\u001b[32m401:\u001b[0m 80.92%\n",
      "\n",
      "\u001b[32m402:\u001b[0m 80.72%\n",
      "\n",
      "\u001b[32m403:\u001b[0m 80.92%\n",
      "\n",
      "\u001b[32m404:\u001b[0m 75.70%\n",
      "\n",
      "\u001b[32m405:\u001b[0m 78.92%\n",
      "\n",
      "\u001b[32m406:\u001b[0m 78.92%\n",
      "\n",
      "\u001b[32m407:\u001b[0m 79.92%\n",
      "\n",
      "\u001b[32m408:\u001b[0m 80.32%\n",
      "\n",
      "\u001b[32m409:\u001b[0m 80.32%\n",
      "\n",
      "\u001b[32m410:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m411:\u001b[0m 80.32%\n",
      "\n",
      "\u001b[32m412:\u001b[0m 79.52%\n",
      "\n",
      "\u001b[32m413:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m414:\u001b[0m 79.72%\n",
      "\n",
      "\u001b[32m415:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m416:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m417:\u001b[0m 79.72%\n",
      "\n",
      "\u001b[32m418:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m419:\u001b[0m 73.69%\n",
      "\n",
      "\u001b[32m420:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m421:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m422:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m423:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m424:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m425:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m426:\u001b[0m 79.92%\n",
      "\n",
      "\u001b[32m427:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m428:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m429:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m430:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m431:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m432:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m433:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m434:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m435:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m436:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m437:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m438:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m439:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m440:\u001b[0m 70.48%\n",
      "\n",
      "\u001b[32m441:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m442:\u001b[0m 78.92%\n",
      "\n",
      "\u001b[32m443:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m444:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m445:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m446:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m447:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m448:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m449:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m450:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m451:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m452:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m453:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m454:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m455:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m456:\u001b[0m 78.51%\n",
      "\n",
      "\u001b[32m457:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m458:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m459:\u001b[0m 80.32%\n",
      "\n",
      "\u001b[32m460:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m461:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m462:\u001b[0m 80.32%\n",
      "\n",
      "\u001b[32m463:\u001b[0m 80.32%\n",
      "\n",
      "\u001b[32m464:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m465:\u001b[0m 80.32%\n",
      "\n",
      "\u001b[32m466:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m467:\u001b[0m 80.52%\n",
      "\n",
      "\u001b[32m468:\u001b[0m 75.70%\n",
      "\n",
      "\u001b[32m469:\u001b[0m 79.52%\n",
      "\n",
      "\u001b[32m470:\u001b[0m 78.92%\n",
      "\n",
      "\u001b[32m471:\u001b[0m 79.92%\n",
      "\n",
      "\u001b[32m472:\u001b[0m 80.32%\n",
      "\n",
      "\u001b[32m473:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m474:\u001b[0m 80.72%\n",
      "\n",
      "\u001b[32m475:\u001b[0m 80.32%\n",
      "\n",
      "\u001b[32m476:\u001b[0m 80.52%\n",
      "\n",
      "\u001b[32m477:\u001b[0m 80.92%\n",
      "\n",
      "\u001b[32m478:\u001b[0m 80.92%\n",
      "\n",
      "\u001b[32m479:\u001b[0m 79.92%\n",
      "\n",
      "\u001b[32m480:\u001b[0m 79.72%\n",
      "\n",
      "\u001b[32m481:\u001b[0m 79.92%\n",
      "\n",
      "\u001b[32m482:\u001b[0m 79.92%\n",
      "\n",
      "\u001b[32m483:\u001b[0m 79.72%\n",
      "\n",
      "\u001b[32m484:\u001b[0m 79.72%\n",
      "\n",
      "\u001b[32m485:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m486:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m487:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m488:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m489:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m490:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m491:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m492:\u001b[0m 78.92%\n",
      "\n",
      "\u001b[32m493:\u001b[0m 79.32%\n",
      "\n",
      "\u001b[32m494:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m495:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m496:\u001b[0m 79.92%\n",
      "\n",
      "\u001b[32m497:\u001b[0m 79.92%\n",
      "\n",
      "\u001b[32m498:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m499:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[32m500:\u001b[0m 79.52%\n",
      "\n",
      "\u001b[32m501:\u001b[0m 80.52%\n",
      "\n",
      "\u001b[32m502:\u001b[0m 80.32%\n",
      "\n",
      "\u001b[32m503:\u001b[0m 78.71%\n",
      "\n",
      "\u001b[32m504:\u001b[0m 80.12%\n",
      "\n",
      "\u001b[31mHIGHEST VALUE =\u001b[0m \u001b[32m398\u001b[0m: 80.92%\n",
      "\u001b[31mLOWEST VALUE =\u001b[0m \u001b[32mbaseline\u001b[0m: 61.65%\n"
     ]
    }
   ],
   "source": [
    "evaluation.accuracy(train_models, 'survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f63b3385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>baseline</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>500</th>\n",
       "      <th>501</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows Ã— 506 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  baseline  model1  model2  3  4  5  6  7  8  ...  495  496  497  \\\n",
       "474         0         0       0       1  0  0  0  1  1  0  ...    1    1    1   \n",
       "370         1         0       1       1  1  1  1  0  0  1  ...    1    1    1   \n",
       "573         1         0       0       1  0  0  0  1  1  0  ...    1    1    1   \n",
       "110         0         0       1       0  1  1  1  0  0  1  ...    0    0    0   \n",
       "167         0         0       0       0  0  0  0  1  1  0  ...    0    0    0   \n",
       "..        ...       ...     ...     ... .. .. .. .. .. ..  ...  ...  ...  ...   \n",
       "735         0         0       0       0  0  0  0  0  0  0  ...    0    0    0   \n",
       "163         0         0       0       0  0  0  0  0  0  0  ...    0    0    0   \n",
       "770         0         0       0       0  0  0  0  0  0  0  ...    0    0    0   \n",
       "196         0         0       0       0  0  0  0  0  0  0  ...    0    0    0   \n",
       "94          0         0       0       0  0  0  0  0  0  0  ...    0    0    0   \n",
       "\n",
       "     498  499  500  501  502  503  504  \n",
       "474    1    1    1    1    0    1    1  \n",
       "370    1    1    1    1    1    0    1  \n",
       "573    1    1    1    1    1    1    1  \n",
       "110    0    0    0    0    0    0    0  \n",
       "167    0    0    0    0    1    1    0  \n",
       "..   ...  ...  ...  ...  ...  ...  ...  \n",
       "735    0    0    0    0    0    0    0  \n",
       "163    0    0    0    0    0    0    0  \n",
       "770    0    0    0    0    0    0    0  \n",
       "196    0    0    0    0    0    0    0  \n",
       "94     0    0    0    0    0    0    0  \n",
       "\n",
       "[498 rows x 506 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938117a5",
   "metadata": {},
   "source": [
    "<a id='Q4'></a>\n",
    "### 4. Use you best 3 models to predict and evaluate on your validate sample.\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "83e0ab7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>features</th>\n",
       "      <th>train_score</th>\n",
       "      <th>validate_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>survived</td>\n",
       "      <td>None</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>478</td>\n",
       "      <td>[pclass, age, alone, sex_male, embark_town_Che...</td>\n",
       "      <td>0.809237</td>\n",
       "      <td>0.738318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>398</td>\n",
       "      <td>[pclass, age, alone, sex_female, embark_town_C...</td>\n",
       "      <td>0.809237</td>\n",
       "      <td>0.733645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>400</td>\n",
       "      <td>[pclass, age, alone, sex_female, embark_town_Q...</td>\n",
       "      <td>0.809237</td>\n",
       "      <td>0.738318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model                                           features  train_score  \\\n",
       "0    survived                                               None   100.000000   \n",
       "479       478  [pclass, age, alone, sex_male, embark_town_Che...     0.809237   \n",
       "399       398  [pclass, age, alone, sex_female, embark_town_C...     0.809237   \n",
       "401       400  [pclass, age, alone, sex_female, embark_town_Q...     0.809237   \n",
       "\n",
       "     validate_score  \n",
       "0        100.000000  \n",
       "479        0.738318  \n",
       "399        0.733645  \n",
       "401        0.738318  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf.sort_values(by='train_score', ascending=False).head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bd0db8",
   "metadata": {},
   "source": [
    "Best 3 Training Models:\n",
    "- 479:\n",
    "- 399:\n",
    "- 401:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11cb19f",
   "metadata": {},
   "source": [
    "<a id='Q5'></a>\n",
    "### 5. Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ac9930f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>features</th>\n",
       "      <th>train_score</th>\n",
       "      <th>validate_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>survived</td>\n",
       "      <td>None</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>495</td>\n",
       "      <td>[pclass, age, fare, alone, sex_female, sex_mal...</td>\n",
       "      <td>0.801205</td>\n",
       "      <td>0.752336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model                                           features  train_score  \\\n",
       "0    survived                                               None   100.000000   \n",
       "496       495  [pclass, age, fare, alone, sex_female, sex_mal...     0.801205   \n",
       "\n",
       "     validate_score  \n",
       "0        100.000000  \n",
       "496        0.752336  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf.sort_values(by='validate_score', ascending=False).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e0798c",
   "metadata": {},
   "source": [
    "Best Validate Model:\n",
    "- 496"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4980da8",
   "metadata": {},
   "source": [
    "<a id='Bonus1'></a>\n",
    "### Bonus-1. How do different strategies for handling the missing values in the age column affect model performance?\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3fd718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be28e416",
   "metadata": {},
   "source": [
    "<a id='Bonus2'></a>\n",
    "### Bonus-2. How do different strategies for encoding sex affect model performance?\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca63ce95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a1659db",
   "metadata": {},
   "source": [
    "<a id='Bonus3'></a>\n",
    "### Bonus-3. scikit-learn's LogisticRegression classifier is actually applying <a href='https://en.wikipedia.org/wiki/Regularized_least_squares'>a regularization penalty to the coefficients</a> by default. This penalty causes the magnitude of the coefficients in the resulting model to be smaller than they otherwise would be. This value can be modified with the C hyper parameter. Small values of C correspond to a larger penalty, and large values of C correspond to a smaller penalty.\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a986db",
   "metadata": {},
   "source": [
    "Try out the following values for C and note how the coefficients and the model's performance on both the dataset it was trained on and on the validate split are affected.\n",
    "\n",
    "C = .01, .1, 1, 10, 100, 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5356678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ba03208",
   "metadata": {},
   "source": [
    "<a id='BonusBonus'></a>\n",
    "### Bonus-Bonus. how does scaling the data interact with your choice of C?\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7265173f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
