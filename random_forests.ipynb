{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ca6cc63",
   "metadata": {},
   "source": [
    "<a id=\"TableOfContents\"></a>\n",
    "# Table of Contents:\n",
    "<li><a href='#imports'>Imports</a></li>\n",
    "<li><a href=\"#Q1\">Question 1</a></li>\n",
    "<li><a href=\"#Q2\">Question 2</a></li>\n",
    "<li><a href=\"#Q3\">Question 3</a></li>\n",
    "<li><a href=\"#Q4\">Question 4</a></li>\n",
    "<li><a href=\"#Q5\">Question 5</a></li>\n",
    "<li><a href=\"#Additional\">Additional Question</a></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86dbbd9",
   "metadata": {},
   "source": [
    "<a id='imports'></a>\n",
    "### IMPORTS:\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b6930fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic sheiza\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Stat/Exploration\n",
    "from scipy import stats\n",
    "\n",
    "# Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# .py files\n",
    "import acquire\n",
    "import prepare\n",
    "import explore\n",
    "import evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a809c62f",
   "metadata": {},
   "source": [
    "Create a new notebook, random_forests, and work with titanic data to do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "309a6b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Cherbourg</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>93.5</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  fare  embark_town  alone  sex_female  \\\n",
       "520         1       1  female  30.0  93.5  Southampton      1           1   \n",
       "\n",
       "     sex_male  embark_town_Cherbourg  embark_town_Queenstown  \\\n",
       "520         0                      0                       0   \n",
       "\n",
       "     embark_town_Southampton  \n",
       "520                        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acquire titanic dataframe\n",
    "titanic = prepare.prep_titanic()\n",
    "titanic.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4584a6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify y_cols\n",
    "y_titanic = 'survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9e3978e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pclass',\n",
       " 'age',\n",
       " 'fare',\n",
       " 'alone',\n",
       " 'sex_female',\n",
       " 'sex_male',\n",
       " 'embark_town_Cherbourg',\n",
       " 'embark_town_Queenstown',\n",
       " 'embark_town_Southampton']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify x_cols\n",
    "x_titanic = titanic.columns.to_list()\n",
    "x_titanic = [col for col in x_titanic if col not in ['survived', 'sex', 'embark_town']]\n",
    "x_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30981ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What column do you want to stratify onsurvived\n",
      "train.shape:(498, 12)\n",
      "validate.shape:(214, 12)\n",
      "test.shape:(179, 12)\n"
     ]
    }
   ],
   "source": [
    "# split data and stratify on survived\n",
    "train, validate, test = prepare.split(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb336099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((498, 12), (214, 12), (179, 12))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify split shapes\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83911c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived\n",
       "474         0\n",
       "370         1\n",
       "573         1\n",
       "110         0\n",
       "167         0\n",
       "..        ...\n",
       "735         0\n",
       "163         0\n",
       "770         0\n",
       "196         0\n",
       "94          0\n",
       "\n",
       "[498 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame(train.survived)\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b00a32",
   "metadata": {},
   "source": [
    "<a id='Q1'></a>\n",
    "### 1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10.\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f082da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = RandomForestClassifier(random_state=43110, min_samples_leaf=1, max_depth=10)\n",
    "clf1.fit(train[x_titanic], train[y_titanic])\n",
    "model1_rf = clf1.predict(train[x_titanic])\n",
    "models['model1_rf'] = model1_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8877e4f8",
   "metadata": {},
   "source": [
    "<a id='Q2'></a>\n",
    "### 2. Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73d37a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:\n",
      "0.96\n",
      "\n",
      "Confusion Matrix:\n",
      "[[174  17]\n",
      " [  2 305]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       307\n",
      "           1       0.99      0.91      0.95       191\n",
      "\n",
      "    accuracy                           0.96       498\n",
      "   macro avg       0.97      0.95      0.96       498\n",
      "weighted avg       0.96      0.96      0.96       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf1_score = round(clf1.score(train[x_titanic], train[y_titanic]), 2)\n",
    "clf1_confusion_matrix = confusion_matrix(models.survived, models.model1_rf, labels=(1, 0))\n",
    "clf1_class_report = classification_report(models.survived, models.model1_rf)\n",
    "print(f'Score:\\n{clf1_score}\\n\\nConfusion Matrix:\\n{clf1_confusion_matrix}\\n\\nClassification Report:\\n{clf1_class_report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5548fe",
   "metadata": {},
   "source": [
    "<a id='Q3'></a>\n",
    "### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4f20e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32msurvived:\u001b[0m 100.00%\n",
      "\n",
      "\u001b[32mmodel1_rf:\u001b[0m 96.18%\n",
      "\n",
      "\u001b[31mHIGHEST VALUE =\u001b[0m \u001b[32mmodel1_rf\u001b[0m: 96.18%\n",
      "\u001b[31mLOWEST VALUE =\u001b[0m \u001b[32mmodel1_rf\u001b[0m: 96.18%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "evaluation.accuracy(models, 'survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9051126d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True Positive Rate\n",
    "round(clf1_confusion_matrix[0, 0] / clf1_confusion_matrix.sum(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "083675e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False Positive Rate\n",
    "round(clf1_confusion_matrix[0, 1] / clf1_confusion_matrix.sum(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddc745a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True Negative Rate\n",
    "round(clf1_confusion_matrix[1, 0] / clf1_confusion_matrix.sum(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4688192a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False Negative Rate\n",
    "round(clf1_confusion_matrix[1, 1] / clf1_confusion_matrix.sum(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be080343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32msurvived:\u001b[0m 100.00%\n",
      "\n",
      "\u001b[32mmodel1_rf:\u001b[0m 91.10%\n",
      "\n",
      "\u001b[31mHIGHEST VALUE =\u001b[0m \u001b[32mmodel1_rf\u001b[0m: 91.10%\n",
      "\u001b[31mLOWEST VALUE =\u001b[0m \u001b[32mmodel1_rf\u001b[0m: 91.10%\n"
     ]
    }
   ],
   "source": [
    "# Precision\n",
    "evaluation.precision(models, 'survived', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb36041e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32msurvived:\u001b[0m 100.00%\n",
      "\n",
      "\u001b[32mmodel1_rf:\u001b[0m 98.86%\n",
      "\n",
      "\u001b[31mHIGHEST VALUE =\u001b[0m \u001b[32mmodel1_rf\u001b[0m: 98.86%\n",
      "\u001b[31mLOWEST VALUE =\u001b[0m \u001b[32mmodel1_rf\u001b[0m: 98.86%\n"
     ]
    }
   ],
   "source": [
    "# Recall\n",
    "evaluation.recall(models, 'survived', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b004cef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32msurvived:\u001b[0m 100.00%\n",
      "\n",
      "\u001b[32mmodel1_rf:\u001b[0m 94.82%\n",
      "\n",
      "\u001b[31mHIGHEST VALUE =\u001b[0m \u001b[32mmodel1_rf\u001b[0m: 94.82%\n",
      "\u001b[31mLOWEST VALUE =\u001b[0m \u001b[32mmodel1_rf\u001b[0m: 94.82%\n"
     ]
    }
   ],
   "source": [
    "# F1 Score\n",
    "evaluation.f1_score(models, 'survived', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0208fc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.95      0.99      0.97       307\\n           1       0.99      0.91      0.95       191\\n\\n    accuracy                           0.96       498\\n   macro avg       0.97      0.95      0.96       498\\nweighted avg       0.96      0.96      0.96       498\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support\n",
    "classification_report(models.survived, models.model1_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd933b2",
   "metadata": {},
   "source": [
    "<a id='Q4'></a>\n",
    "### 4. Run through steps increasing your min_samples_leaf and decreasing your max_depth.\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b04a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_samples_leaf = 2, max_depth = 9\n",
    "clf2 = RandomForestClassifier(random_state=43110, min_samples_leaf=2, max_depth=9)\n",
    "clf2.fit(train[x_titanic], train[y_titanic])\n",
    "model2_rf = clf2.predict(train[x_titanic])\n",
    "models['model2_rf'] = model2_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fce86675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_samples_leaf = 3, max_depth = 8\n",
    "clf3 = RandomForestClassifier(random_state=43110, min_samples_leaf=3, max_depth=8)\n",
    "clf3.fit(train[x_titanic], train[y_titanic])\n",
    "model3_rf = clf3.predict(train[x_titanic])\n",
    "models['model3_rf'] = model3_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d607f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_samples_leaf = 4, max_depth = 7\n",
    "clf4 = RandomForestClassifier(random_state=43110, min_samples_leaf=4, max_depth=7)\n",
    "clf4.fit(train[x_titanic], train[y_titanic])\n",
    "model4_rf = clf4.predict(train[x_titanic])\n",
    "models['model4_rf'] = model4_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "310e578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_samples_leaf = 5, max_depth = 6\n",
    "clf5 = RandomForestClassifier(random_state=43110, min_samples_leaf=5, max_depth=6)\n",
    "clf5.fit(train[x_titanic], train[y_titanic])\n",
    "model5_rf = clf5.predict(train[x_titanic])\n",
    "models['model5_rf'] = model5_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48552d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_samples_leaf = 6, max_depth = 5\n",
    "clf6 = RandomForestClassifier(random_state=43110, min_samples_leaf=6, max_depth=5)\n",
    "clf6.fit(train[x_titanic], train[y_titanic])\n",
    "model6_rf = clf6.predict(train[x_titanic])\n",
    "models['model6_rf'] = model6_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "142cc0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_samples_leaf = 7, max_depth = 4\n",
    "clf7 = RandomForestClassifier(random_state=43110, min_samples_leaf=7, max_depth=4)\n",
    "clf7.fit(train[x_titanic], train[y_titanic])\n",
    "model7_rf = clf7.predict(train[x_titanic])\n",
    "models['model7_rf'] = model7_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29ae8fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_samples_leaf = 8, max_depth = 3\n",
    "clf8 = RandomForestClassifier(random_state=43110, min_samples_leaf=8, max_depth=3)\n",
    "clf8.fit(train[x_titanic], train[y_titanic])\n",
    "model8_rf = clf8.predict(train[x_titanic])\n",
    "models['model8_rf'] = model8_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c27f71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_samples_leaf = 9, max_depth = 2\n",
    "clf9 = RandomForestClassifier(random_state=43110, min_samples_leaf=9, max_depth=2)\n",
    "clf9.fit(train[x_titanic], train[y_titanic])\n",
    "model9_rf = clf9.predict(train[x_titanic])\n",
    "models['model9_rf'] = model9_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25e8c178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_samples_leaf = 10, max_depth = 1\n",
    "clf10 = RandomForestClassifier(random_state=43110, min_samples_leaf=10, max_depth=1)\n",
    "clf10.fit(train[x_titanic], train[y_titanic])\n",
    "model10_rf = clf10.predict(train[x_titanic])\n",
    "models['model10_rf'] = model10_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0b73dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>model1_rf</th>\n",
       "      <th>model2_rf</th>\n",
       "      <th>model3_rf</th>\n",
       "      <th>model4_rf</th>\n",
       "      <th>model5_rf</th>\n",
       "      <th>model6_rf</th>\n",
       "      <th>model7_rf</th>\n",
       "      <th>model8_rf</th>\n",
       "      <th>model9_rf</th>\n",
       "      <th>model10_rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  model1_rf  model2_rf  model3_rf  model4_rf  model5_rf  \\\n",
       "431         1          1          1          1          1          1   \n",
       "\n",
       "     model6_rf  model7_rf  model8_rf  model9_rf  model10_rf  \n",
       "431          1          1          1          1           1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2209490",
   "metadata": {},
   "source": [
    "<a id='Q5'></a>\n",
    "### 5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c43bb412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32msurvived:\u001b[0m 100.00%\n",
      "\n",
      "\u001b[32mmodel1_rf:\u001b[0m 94.82%\n",
      "\n",
      "\u001b[32mmodel2_rf:\u001b[0m 87.29%\n",
      "\n",
      "\u001b[32mmodel3_rf:\u001b[0m 84.18%\n",
      "\n",
      "\u001b[32mmodel4_rf:\u001b[0m 82.72%\n",
      "\n",
      "\u001b[32mmodel5_rf:\u001b[0m 80.81%\n",
      "\n",
      "\u001b[32mmodel6_rf:\u001b[0m 75.53%\n",
      "\n",
      "\u001b[32mmodel7_rf:\u001b[0m 74.55%\n",
      "\n",
      "\u001b[32mmodel8_rf:\u001b[0m 72.52%\n",
      "\n",
      "\u001b[32mmodel9_rf:\u001b[0m 71.78%\n",
      "\n",
      "\u001b[32mmodel10_rf:\u001b[0m 71.78%\n",
      "\n",
      "\u001b[31mHIGHEST VALUE =\u001b[0m \u001b[32mmodel1_rf\u001b[0m: 94.82%\n",
      "\u001b[31mLOWEST VALUE =\u001b[0m \u001b[32mmodel9_rf\u001b[0m: 71.78%\n"
     ]
    }
   ],
   "source": [
    "evaluation.f1_score(models, 'survived', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363b00b6",
   "metadata": {},
   "source": [
    "Model-1 performed the best via F-1 Score being the highest...\n",
    "\n",
    "Something to note, as min_samples_leaf increased and max_depth decreased, the scores consistently  got lower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfb1a57",
   "metadata": {},
   "source": [
    "<a id='Additional'></a>\n",
    "### Additional. After making a few models, which one has the best performance (or closest metrics) on both train and validate?\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42f548d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [\n",
    "    clf1, \n",
    "    clf2, \n",
    "    clf3, \n",
    "    clf4, \n",
    "    clf5, \n",
    "    clf6, \n",
    "    clf7, \n",
    "    clf8, \n",
    "    clf9, \n",
    "    clf10\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a57a07e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mmodel1\u001b[0m Train Score: 0.96\n",
      "\u001b[32mmodel1\u001b[0m Validate Score: 0.78\n",
      "\n",
      "\u001b[32mmodel2\u001b[0m Train Score: 0.91\n",
      "\u001b[32mmodel2\u001b[0m Validate Score: 0.78\n",
      "\n",
      "\u001b[32mmodel3\u001b[0m Train Score: 0.89\n",
      "\u001b[32mmodel3\u001b[0m Validate Score: 0.79\n",
      "\n",
      "\u001b[32mmodel4\u001b[0m Train Score: 0.88\n",
      "\u001b[32mmodel4\u001b[0m Validate Score: 0.79\n",
      "\n",
      "\u001b[32mmodel5\u001b[0m Train Score: 0.87\n",
      "\u001b[32mmodel5\u001b[0m Validate Score: 0.79\n",
      "\n",
      "\u001b[32mmodel6\u001b[0m Train Score: 0.84\n",
      "\u001b[32mmodel6\u001b[0m Validate Score: 0.78\n",
      "\n",
      "\u001b[32mmodel7\u001b[0m Train Score: 0.83\n",
      "\u001b[32mmodel7\u001b[0m Validate Score: 0.79\n",
      "\n",
      "\u001b[32mmodel8\u001b[0m Train Score: 0.81\n",
      "\u001b[32mmodel8\u001b[0m Validate Score: 0.75\n",
      "\n",
      "\u001b[32mmodel9\u001b[0m Train Score: 0.79\n",
      "\u001b[32mmodel9\u001b[0m Validate Score: 0.74\n",
      "\n",
      "\u001b[32mmodel10\u001b[0m Train Score: 0.79\n",
      "\u001b[32mmodel10\u001b[0m Validate Score: 0.74\n",
      "\n",
      "\u001b[31mHIGHEST VALUE (TRAIN)\u001b[0m = 1: 0.96\n",
      "\u001b[31mLOWEST VALUE (TRAIN)\u001b[0m = 9: 0.79\n",
      "\u001b[31mHIGHEST VALUE (VALIDATE)\u001b[0m = 3: 0.79\n",
      "\u001b[31mLOWEST VALUE (VALIDATE)\u001b[0m = 9: 0.74\n",
      "\u001b[31mHIGHEST DIFF\u001b[0m = 1: 0.17999999999999994\n",
      "\u001b[31mLOWEST DIFF\u001b[0m = 7: 0.039999999999999925\n"
     ]
    }
   ],
   "source": [
    "train_dict = {}\n",
    "validate_dict = {}\n",
    "performance_dict = {}\n",
    "modelnum = 0\n",
    "for x in models_list:\n",
    "    modelnum += 1\n",
    "    train_score = round(x.score(train[x_titanic], train[y_titanic]), 2)\n",
    "    validate_score = round(x.score(validate[x_titanic], validate[y_titanic]), 2)\n",
    "    train_dict[modelnum] = train_score\n",
    "    validate_dict[modelnum] = validate_score\n",
    "    diff = abs(train_score - validate_score)\n",
    "    performance_dict[modelnum] = diff\n",
    "    print(f'\\033[32mmodel{modelnum}\\033[0m Train Score: {train_score}')\n",
    "    print(f'\\033[32mmodel{modelnum}\\033[0m Validate Score: {validate_score}\\n')\n",
    "train_max_model = max(train_dict, key=train_dict.get)\n",
    "train_max_pct = train_dict[train_max_model]\n",
    "train_min_model = min(train_dict, key=train_dict.get)\n",
    "train_min_pct = train_dict[train_min_model]\n",
    "validate_max_model = max(validate_dict, key=validate_dict.get)\n",
    "validate_max_pct = validate_dict[validate_max_model]\n",
    "validate_min_model = min(validate_dict, key=validate_dict.get)\n",
    "validate_min_pct = validate_dict[validate_min_model]\n",
    "performance_lowest_model = max(performance_dict, key=performance_dict.get)\n",
    "performance_lowest_pct = performance_dict[performance_lowest_model]\n",
    "performance_highest_model = min(performance_dict, key=performance_dict.get)\n",
    "performance_highest_pct = performance_dict[performance_highest_model]\n",
    "print(f'\\033[31mHIGHEST VALUE (TRAIN)\\033[0m = {train_max_model}: {train_max_pct}')\n",
    "print(f'\\033[31mLOWEST VALUE (TRAIN)\\033[0m = {train_min_model}: {train_min_pct}')\n",
    "print(f'\\033[31mHIGHEST VALUE (VALIDATE)\\033[0m = {validate_max_model}: {validate_max_pct}')\n",
    "print(f'\\033[31mLOWEST VALUE (VALIDATE)\\033[0m = {validate_min_model}: {validate_min_pct}')\n",
    "print(f'\\033[31mHIGHEST DIFF\\033[0m = {performance_lowest_model}: {performance_lowest_pct}')\n",
    "print(f'\\033[31mLOWEST DIFF\\033[0m = {performance_highest_model}: {performance_highest_pct}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cced035",
   "metadata": {},
   "source": [
    "Model-7 has the lowest difference between train and validate scores\n",
    "\n",
    "Model-7 restrictions: \n",
    "- min_samples_leaf = 7\n",
    "- max_depth = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb4a3464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mmodel1\u001b[0m Train Score: 0.96\n",
      "\u001b[32mmodel1\u001b[0m Validate Score: 0.78\n",
      "\n",
      "\u001b[32mmodel2\u001b[0m Train Score: 0.91\n",
      "\u001b[32mmodel2\u001b[0m Validate Score: 0.78\n",
      "\n",
      "\u001b[32mmodel3\u001b[0m Train Score: 0.89\n",
      "\u001b[32mmodel3\u001b[0m Validate Score: 0.79\n",
      "\n",
      "\u001b[32mmodel4\u001b[0m Train Score: 0.88\n",
      "\u001b[32mmodel4\u001b[0m Validate Score: 0.79\n",
      "\n",
      "\u001b[32mmodel5\u001b[0m Train Score: 0.87\n",
      "\u001b[32mmodel5\u001b[0m Validate Score: 0.79\n",
      "\n",
      "\u001b[32mmodel6\u001b[0m Train Score: 0.84\n",
      "\u001b[32mmodel6\u001b[0m Validate Score: 0.78\n",
      "\n",
      "\u001b[32mmodel7\u001b[0m Train Score: 0.83\n",
      "\u001b[32mmodel7\u001b[0m Validate Score: 0.79\n",
      "\n",
      "\u001b[32mmodel8\u001b[0m Train Score: 0.81\n",
      "\u001b[32mmodel8\u001b[0m Validate Score: 0.75\n",
      "\n",
      "\u001b[32mmodel9\u001b[0m Train Score: 0.79\n",
      "\u001b[32mmodel9\u001b[0m Validate Score: 0.74\n",
      "\n",
      "\u001b[32mmodel10\u001b[0m Train Score: 0.79\n",
      "\u001b[32mmodel10\u001b[0m Validate Score: 0.74\n",
      "\n",
      "\u001b[31mHIGHEST VALUE (TRAIN)\u001b[0m = 1: 0.96\n",
      "\u001b[31mLOWEST VALUE (TRAIN)\u001b[0m = 9: 0.79\n",
      "\u001b[31mHIGHEST VALUE (VALIDATE)\u001b[0m = 3: 0.79\n",
      "\u001b[31mLOWEST VALUE (VALIDATE)\u001b[0m = 9: 0.74\n",
      "\u001b[31mHIGHEST DIFF\u001b[0m = 1: 0.17999999999999994\n",
      "\u001b[31mLOWEST DIFF\u001b[0m = 7: 0.039999999999999925\n"
     ]
    }
   ],
   "source": [
    "# Testing evaluation.py function\n",
    "evaluation.train_val_scores(train, validate, x_titanic, y_titanic, models_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
