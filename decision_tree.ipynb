{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60d7bbb6",
   "metadata": {},
   "source": [
    "<a id=\"TableOfContents\"></a>\n",
    "# TABLE OF CONTENTS:\n",
    "<li><a href='#imports'>Imports</a></li>\n",
    "<li><a href=\"#Q1\">Question 1</a></li>\n",
    "<li><a href=\"#Q2\">Question 2</a></li>\n",
    "<li><a href=\"#Q3\">Question 3</a></li>\n",
    "<li><a href=\"#Q4\">Question 4</a></li>\n",
    "<li><a href=\"#Q5\">Question 5</a></li>\n",
    "<li><a href=\"#Q6\">Question 6</a></li>\n",
    "<li><a href=\"#Q7\">Question 7</a></li>\n",
    "<li><a href=\"#Bonus1\">Bonus-1</a></li>\n",
    "<li><a href=\"#Bonus2\">Bonus-2</a></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff27fbe",
   "metadata": {},
   "source": [
    "<a id='imports'></a>\n",
    "# IMPORTS:\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c66374e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to f-string expression (model.py, line 71)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/usr/local/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3457\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_14840/1206172015.py\"\u001b[0;36m, line \u001b[0;32m21\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    import model\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/manupfool/codeup-data-science/classification-exercises/model.py\"\u001b[0;36m, line \u001b[0;32m71\u001b[0m\n\u001b[0;31m    f'clf{modelnum}' = DecisionTreeClassifier(max_depth=i)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to f-string expression\n"
     ]
    }
   ],
   "source": [
    "# Basic sheiza\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Stats/Explore\n",
    "from scipy import stats\n",
    "\n",
    "# Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# .py file(s)\n",
    "import acquire\n",
    "import prepare\n",
    "import explore\n",
    "import evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f23686",
   "metadata": {},
   "source": [
    "Using the titanic data, in your classification-exercises repository, create a notebook, decision_tree.ipynb where you will do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb04e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire titanic dataframe\n",
    "titanic = prepare.prep_titanic()\n",
    "titanic.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a6ceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify y_cols\n",
    "y_titanic = 'survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3679c55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify x_cols\n",
    "x_titanic = titanic.columns.to_list()\n",
    "x_titanic = [col for col in x_titanic if col not in ['survived', 'sex', 'embark_town']]\n",
    "x_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543f7502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data and stratify on survived\n",
    "titanic_train, titanic_validate, titanic_test = prepare.split(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f91e969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify split shapes\n",
    "titanic_train.shape, titanic_validate.shape, titanic_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028279f4",
   "metadata": {},
   "source": [
    "<a id='Q1'></a>\n",
    "### 1. What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy.\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4afde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# titanic models sets\n",
    "titanic_models = titanic_train['survived']\n",
    "titanic_models = pd.DataFrame(titanic_models)\n",
    "titanic_models = titanic_models.rename(columns={'survived' : 'actual'})\n",
    "titanic_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5879ceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline is '0' or 'DID NOT survive'\n",
    "titanic.survived.value_counts()\n",
    "titanic_models['baseline'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfbadc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline accuracy is 61.62%\n",
    "evaluation.accuracy(titanic_models, 'actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3956e0",
   "metadata": {},
   "source": [
    "<a id='Q2'></a>\n",
    "### 2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6088b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train[x_titanic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629b4821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 1st model as decision tree\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf1.fit(titanic_train[x_titanic], titanic_train[y_titanic])\n",
    "model1_dt = clf1.predict(titanic_train[x_titanic])\n",
    "titanic_models['model1_dt'] = model1_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b95230",
   "metadata": {},
   "source": [
    "<a id='Q3'></a>\n",
    "### 3. Evaluate your in-sample results using the model score, confusion matrix, and classification report.\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3d9647",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1_score = clf1.score(titanic_train[x_titanic], titanic_train[y_titanic])\n",
    "clf1_confusion_matrix = confusion_matrix(titanic_models.actual, model1_dt)\n",
    "clf1_class_report = classification_report(titanic_models.actual, model1_dt)\n",
    "print(f'clf1 score:\\n{clf1_score}\\n')\n",
    "print(f'clf1 confusion matrix:\\n{clf1_confusion_matrix}\\n')\n",
    "print(f'clf1 classification report:\\n{clf1_class_report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39965420",
   "metadata": {},
   "source": [
    "<a id='Q4'></a>\n",
    "### 4. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1fb8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "evaluation.accuracy(titanic_models, 'actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ef9b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True positive rate\n",
    "model1_dt_matrix = confusion_matrix(titanic_models.actual, titanic_models.model1_dt, labels=(0, 1))\n",
    "round(model1_dt_matrix[1, 1] / model1_dt_matrix.sum(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e9c6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# False Positive Rate\n",
    "round(model1_dt_matrix[0, 1] / model1_dt_matrix.sum(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0dd907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True Negative Rate\n",
    "round(model1_dt_matrix[0, 0] / model1_dt_matrix.sum(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f5cf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# False Negative Rate\n",
    "round(model1_dt_matrix[1, 0] / model1_dt_matrix.sum(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacfd66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(titanic_models.actual, model1_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f667a883",
   "metadata": {},
   "source": [
    "<a id='Q5'></a>\n",
    "### 5. Run through steps 2-4 using a different max_depth value.\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77c9eaa",
   "metadata": {},
   "source": [
    "##### 5a. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8fedae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No restricion depth = 15\n",
    "plot_tree(clf1, feature_names=x_titanic)\n",
    "plt.show()\n",
    "clf1.tree_.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadcf220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict from 15 to 10\n",
    "clf2 = DecisionTreeClassifier(max_depth=10)\n",
    "clf2.fit(titanic_train[x_titanic], titanic_train[y_titanic])\n",
    "model2_dt = clf2.predict(titanic_train[x_titanic])\n",
    "titanic_models['model2_dt'] = model2_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818843ca",
   "metadata": {},
   "source": [
    "##### 5b. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071370c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2_score = clf2.score(titanic_train[x_titanic], titanic_train[y_titanic])\n",
    "clf2_confusion_matrix = confusion_matrix(titanic_models.actual, titanic_models.model2_dt, labels=(0, 1))\n",
    "clf2_class_report = classification_report(titanic_models.actual, titanic_models.model2_dt)\n",
    "print(f'clf2 score:\\n{clf2_score}\\n')\n",
    "print(f'clf2 confusion matrix:\\n{clf2_confusion_matrix}\\n')\n",
    "print(f'clf2 classification report:\\n{clf2_class_report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fbc3bc",
   "metadata": {},
   "source": [
    "##### 5c. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094fec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy, precision, recall, f-1 score, support\n",
    "clf2_class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a57a742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True positive rate\n",
    "round(clf2_confusion_matrix[1, 1] / clf2_confusion_matrix.sum(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c8ce24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# False Positive Rate\n",
    "round(clf2_confusion_matrix[0, 1] / clf2_confusion_matrix.sum(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d223c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True Negative Rate\n",
    "round(clf2_confusion_matrix[0, 0] / clf2_confusion_matrix.sum(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a11acf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# False Negative Rate\n",
    "round(clf2_confusion_matrix[1, 0] / clf2_confusion_matrix.sum(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34feb2c1",
   "metadata": {},
   "source": [
    "<a id='Q6'></a>\n",
    "### 6. Which model performs better on your in-sample data?\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d122d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.f1_score(titanic_models, 'actual', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d01b43c",
   "metadata": {},
   "source": [
    "Model-1 Performed the best (Had no restrictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c2a096",
   "metadata": {},
   "source": [
    "<a id='Q7'></a>\n",
    "### 7. Which model performs best on your out-of-sample data, the validate set?\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f4b764",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1_train_score = round(clf1.score(titanic_train[x_titanic], titanic_train[y_titanic]), 2)\n",
    "clf1_validate_score = round(clf1.score(titanic_validate[x_titanic], titanic_validate[y_titanic]), 2)\n",
    "clf2_train_score = round(clf2.score(titanic_train[x_titanic], titanic_train[y_titanic]), 2)\n",
    "clf2_validate_score = round(clf2.score(titanic_validate[x_titanic], titanic_validate[y_titanic]), 2)\n",
    "print(f'clf1 Train: {clf1_train_score}\\nclf1 Validate: {clf1_validate_score}\\nclf2 Train: {clf2_train_score}\\nclf2 Validate: {clf2_validate_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd727e8",
   "metadata": {},
   "source": [
    "Model-2 performed the best (Restricted depth from 15 to 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7194b6c7",
   "metadata": {},
   "source": [
    "<a id='Bonus1'></a>\n",
    "### BONUS-1. Work through these same exercises using the Telco dataset.\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf3a31f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2f560ac",
   "metadata": {},
   "source": [
    "<a id='Bonus2'></a>\n",
    "### BONUS-2. Experiment with this model on other datasets with a higher number of output classes.\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e35b39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdict= {\n",
    "    'model' : [1, 2, 3],\n",
    "    'train' : [10.00, 23.45, 44.13],\n",
    "    'val' : [20.00, 33.45, 54.13],\n",
    "    'diff' : [10, 10, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846a7b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.DataFrame(testdict)\n",
    "testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da795c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.deci"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
